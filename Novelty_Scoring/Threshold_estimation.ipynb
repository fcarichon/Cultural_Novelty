{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edff5772-3e0d-4c3b-a48e-841127b3a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import json\n",
    "import re\n",
    "import statistics\n",
    "from utils import data_analysis, pmi, pmi_to_dict, docs_distribution, new_distribution\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Novelty import Newness, Uniqueness, Difference\n",
    "from Surprise import Surprise\n",
    "from utils import pmi, data_analysis, docs_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e556c4d-4603-4875-80b2-b68c945d22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Divergences import Jensen_Shannon\n",
    "import numpy as np\n",
    "from Scoring import compute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b1e749d-821f-4c33-8d06-43e91d6d3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = './Recipe_dataset/RecipeFullDataset/'\n",
    "save_path = './Recipe_dataset/Recipe_with_scores/'\n",
    "filenames = next(walk(my_path), (None, None, []))[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c486bf6-1fd5-462f-8ddb-e2e731c34ba8",
   "metadata": {},
   "source": [
    "### First estimation for the Individual term divergence for newness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac9e09-720c-4b30-abcd-cf8b412c415c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds_all = []\n",
    "JS = Jensen_Shannon() \n",
    "means = []\n",
    "std_devs = []\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    file_recette = filenames[i]\n",
    "    #Opening Json file with al lrecipes infos\n",
    "    file_path = my_path + file_recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    #### COLLECTING ALL NECESSARY INFO\n",
    "    KB_recettes, _ = data_analysis(recipe_dict)\n",
    "    #print('Knowledge base size : ', len(KB_recettes))\n",
    "    if len(KB_recettes) <= 0:\n",
    "        continue\n",
    "\n",
    "\n",
    "    recette_variations = KB_recettes\n",
    "    KB_matrix,  KB_dist, Count_matrix = docs_distribution(KB_recettes, recette_variations)\n",
    "    KB_size = list(range(KB_matrix.shape[0]))\n",
    "    \n",
    "    #Let's samples 15 recipe max per round -- we don't need more than that for threshold estimate\n",
    "    lengths = min(len(KB_recettes), 50)\n",
    "    for j in range(lengths):\n",
    "\n",
    "        select_variation = KB_size + [len(KB_size)+j]\n",
    "        NewKB_dist, variation_dist = new_distribution(Count_matrix, select_variation)\n",
    "        \n",
    "        KB_updated = KB_recettes + [KB_recettes[j]]\n",
    "\n",
    "        JSD_vector = JS.linear_JSD(KB_dist, variation_dist) ## Here I get the individual divergence of each terms compare to the other -- now I want an average and a standard dev for that doc\n",
    "        #appear = []\n",
    "        #disappear = []\n",
    "        #for k in range(len(JSD_vector)):\n",
    "        #    if JSD_vector[k] != 0:\n",
    "                #print(variation_dist[k] / (KB_dist[k]+1e-10))\n",
    "         #       if variation_dist[k] / (KB_dist[k]+1e-10) > 0:\n",
    "         #           if KB_dist[k] > 0:\n",
    "         #               appear.append(variation_dist[k] / (KB_dist[k]))\n",
    "         #       if KB_dist[k] / (variation_dist[k]+1e-10) > 0:\n",
    "         #           if variation_dist[k] > 0:\n",
    "         #               disappear.append(KB_dist[k] / (variation_dist[k]))\n",
    "       # if len(appear) >1:\n",
    "       #     avg_a = statistics.mean(appear)\n",
    "       #     std_a = statistics.stdev(appear)\n",
    "       # if len(disappear) >1:\n",
    "       #     avg_d = statistics.mean(disappear)\n",
    "        #    std_d = statistics.stdev(disappear)\n",
    "        for i in range(len(JSD_vector)):\n",
    "            if variation_dist[i] > KB_dist[i]:\n",
    "                means.append(JSD_vector[i])\n",
    "        \n",
    "        #means.append(avg_a)\n",
    "        #means.append(avg_d)\n",
    "        #std_devs.append(std_a)\n",
    "        #std_devs.append(std_d)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40d3ae3a-3eef-42ad-97b5-38c2ca74cf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average divergence of each terms for all documents in training is :  0.003309394000348933\n",
      "The average standard deviation of the divergence of each terms for all documents in training is :  0.004848692406032415\n"
     ]
    }
   ],
   "source": [
    "print('The average divergence of each terms for all documents in training is : ', statistics.mean(means))\n",
    "print('The average standard deviation of the divergence of each terms for all documents in training is : ', statistics.stdev(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbb8a57d-d305-4292-a39f-78d529eae754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▌                                              | 210/501 [31:53<44:11,  9.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 60\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#return newness, novelty_new, uniqueness, novelty_uniq, diff_ratio, nolvety_diff, neighbor_dist, newratio_surprise_rate, newn_suprise, dist_surprise, uniq_surprise\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#newness1, _, uniqueness1, _, difference1, _, neighboroud_distance, new_surprise1, _, dist_surprise1, _ = compute_scores(KB_matrix, KB_dist, NewKB_dist, variation_dist, EB_PMI, dict_know_pmi, New_EB_PMI, neighbor_dist=neighboroud_distance)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#newness2, _, uniqueness2, _, difference2, _, neighboroud_distance, _, _, _, _ = compute_scores(KB_matrix, KB_dist, NewKB_dist, variation_dist, EB_PMI, dict_know_pmi, New_EB_PMI, neighbor_dist=neighboroud_distance, newness_type='prob', uniq_type='shift', diff_type='global')   \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#difference1, _ = difference.ratio_to_all(neighbor_dist, thr_diff=0.4177)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#difference2, _ = difference.ratio_to_neighbors(neighbor_dist, thr_diff=0.1564)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m surprise \u001b[38;5;241m=\u001b[39m Surprise(New_EB_PMI)\n\u001b[1;32m---> 60\u001b[0m new_surprise1, _ \u001b[38;5;241m=\u001b[39m surprise\u001b[38;5;241m.\u001b[39mnew_surprise(EB_PMI, thr_surp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0172\u001b[39m)   \u001b[38;5;66;03m### Devrait être 0.0172\u001b[39;00m\n\u001b[0;32m     61\u001b[0m dist_surprise1, _ \u001b[38;5;241m=\u001b[39m surprise\u001b[38;5;241m.\u001b[39muniq_surprise(dict_know_pmi, eps\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00\u001b[39m, thr_surp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.036\u001b[39m)   \u001b[38;5;66;03m### Devrait être 0.036\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#, newness_type='div', uniq_type='dist', diff_type='local',\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#newness1s.append(newness1)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#newness2s.append(newness2)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#difference1s.append(difference1)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#difference2s.append(difference2)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\All Files\\Python Codes\\Cultural Novelty\\Surprise.py:44\u001b[0m, in \u001b[0;36mSurprise.new_surprise\u001b[1;34m(self, pmi_known, thr_surp)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thresholds_all = []\n",
    "JS = Jensen_Shannon() \n",
    "means = []\n",
    "std_devs = []\n",
    "newness1s, newness2s, uniqueness1s, difference1s, new_surprise1s, dist_surprise1s, uniqueness2s, difference2s = [],[],[],[],[],[],[],[]\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    file_recette = filenames[i]\n",
    "    #Opening Json file with al lrecipes infos\n",
    "    file_path = my_path + file_recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    #### COLLECTING ALL NECESSARY INFO\n",
    "    KB_recettes, _ = data_analysis(recipe_dict)\n",
    "    #print('Knowledge base size : ', len(KB_recettes))\n",
    "    if len(KB_recettes) <= 0:\n",
    "        continue\n",
    "\n",
    "    lengths = min(len(KB_recettes), 50)\n",
    "    if lengths >= 50:\n",
    "        KB_recettes = KB_recettes[0:50]\n",
    "        \n",
    "    recette_variations = KB_recettes\n",
    "    KB_matrix,  KB_dist, Count_matrix = docs_distribution(KB_recettes, recette_variations)\n",
    "    KB_size = list(range(KB_matrix.shape[0]))\n",
    "    neighbor_dist  = 0. \n",
    "    #Let's samples 15 recipe max per round -- we don't need more than that for threshold estimate\n",
    "    KB_texts = ' '.join(KB_recettes).split()\n",
    "    EB_PMI = pmi(KB_texts)\n",
    "    dict_know_pmi = pmi_to_dict(EB_PMI)\n",
    "    \n",
    "    for j in range(lengths):\n",
    "\n",
    "        select_variation = KB_size + [len(KB_size)+j]\n",
    "        NewKB_dist, variation_dist = new_distribution(Count_matrix, select_variation)\n",
    "\n",
    "        KB_updated = KB_recettes + [recette_variations[j]]\n",
    "        updated_text = ' '.join(KB_updated).split()\n",
    "        New_EB_PMI = pmi(updated_text)\n",
    "        \n",
    "        #return newness, novelty_new, uniqueness, novelty_uniq, diff_ratio, nolvety_diff, neighbor_dist, newratio_surprise_rate, newn_suprise, dist_surprise, uniq_surprise\n",
    "        #newness1, _, uniqueness1, _, difference1, _, neighboroud_distance, new_surprise1, _, dist_surprise1, _ = compute_scores(KB_matrix, KB_dist, NewKB_dist, variation_dist, EB_PMI, dict_know_pmi, New_EB_PMI, neighbor_dist=neighboroud_distance)\n",
    "        #newness2, _, uniqueness2, _, difference2, _, neighboroud_distance, _, _, _, _ = compute_scores(KB_matrix, KB_dist, NewKB_dist, variation_dist, EB_PMI, dict_know_pmi, New_EB_PMI, neighbor_dist=neighboroud_distance, newness_type='prob', uniq_type='shift', diff_type='global')   \n",
    "\n",
    "        #newness = Newness(KB_dist, variation_dist)\n",
    "        #newness1, _ = newness.divergent_terms(thr_div=0.0041, thr_new=0.0014)\n",
    "        #newness2, _ = newness.probable_terms(thr_prob= 57.14, thr_new=0.0014)\n",
    "    \n",
    "        #uniqueness = Uniqueness(KB_dist)\n",
    "        #uniqueness1, _ = uniqueness.dist_to_proto(variation_dist, thr_uniq=0.527)\n",
    "        #uniqueness2, _ = uniqueness.proto_dist_shift(NewKB_dist, thr_uniqp=0.1295)\n",
    "        \n",
    "        #difference = Difference(KB_matrix, variation_dist, N=3)\n",
    "        #if neighbor_dist==0.:\n",
    "        #    neighbor_dist = difference.dist_estimate()\n",
    "        #difference1, _ = difference.ratio_to_all(neighbor_dist, thr_diff=0.4177)\n",
    "        #difference2, _ = difference.ratio_to_neighbors(neighbor_dist, thr_diff=0.1564)\n",
    "\n",
    "        surprise = Surprise(New_EB_PMI)\n",
    "        new_surprise1, _ = surprise.new_surprise(EB_PMI, thr_surp=0.0172)   ### Devrait être 0.0172\n",
    "        dist_surprise1, _ = surprise.uniq_surprise(dict_know_pmi, eps= 0.00, thr_surp=0.036)   ### Devrait être 0.036\n",
    "\n",
    "        #, newness_type='div', uniq_type='dist', diff_type='local',\n",
    "        #newness1s.append(newness1)\n",
    "        #newness2s.append(newness2)\n",
    "        #uniqueness1s.append(uniqueness1)\n",
    "        #uniqueness2s.append(uniqueness2)\n",
    "        #difference1s.append(difference1)\n",
    "        #difference2s.append(difference2)\n",
    "        new_surprise1s.append(new_surprise1)\n",
    "        dist_surprise1s.append(dist_surprise1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8625d958-db6e-41ee-8ca2-a290eb181fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "The average new_surprise :  0.0011671448974807505\n",
      "The average standard deviation new_surprise :  0.0014953203307006618\n",
      "=====================================================\n",
      "The average dist_surprise :  0.0003664058656484847\n",
      "The average standard deviation dist_surprise :  0.0004558997701943524\n"
     ]
    }
   ],
   "source": [
    "#print('The average newness 1 : ', statistics.mean(newness1s))\n",
    "#print('The average standard deviation newness 1 : ', statistics.stdev(newness1s))\n",
    "#print('=====================================================')\n",
    "#print('The average newness 2 : ', statistics.mean(newness2s))\n",
    "#print('The average standard deviation newness 2 : ', statistics.stdev(newness2s))\n",
    "#print('=====================================================')\n",
    "#print('The average uniqueness 1 : ', statistics.mean(uniqueness1s))\n",
    "#print('The average standard deviation uniqueness 1 : ', statistics.stdev(uniqueness1s))\n",
    "#print('=====================================================')\n",
    "#print('The average uniqueness 2 : ', statistics.mean(uniqueness2s))\n",
    "#print('The average standard deviation uniqueness 2 : ', statistics.stdev(uniqueness2s))\n",
    "#print('=====================================================')\n",
    "#print('The average difference 1 : ', statistics.mean(difference1s))\n",
    "#print('The average standard deviation difference 1 : ', statistics.stdev(difference1s))\n",
    "#print('=====================================================')\n",
    "#print('The average difference 2 : ', statistics.mean(difference2s))\n",
    "#print('The average standard deviation difference 2 : ', statistics.stdev(difference2s))\n",
    "print('=====================================================')\n",
    "print('The average new_surprise : ', statistics.mean(new_surprise1s))\n",
    "print('The average standard deviation new_surprise : ', statistics.stdev(new_surprise1s))\n",
    "print('=====================================================')\n",
    "print('The average dist_surprise : ', statistics.mean(dist_surprise1s))\n",
    "print('The average standard deviation dist_surprise : ', statistics.stdev(dist_surprise1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2e6df-fdd5-4853-9891-af3ab71b3328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
