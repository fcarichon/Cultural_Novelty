{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e11ea554-5efd-442d-bffa-586d5191e5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "import json\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "import os\n",
    "from os import walk\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e727565-907f-4a16-9682-bcbe30204f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "my_path = './Recipe_dataset/RecipeFullDataset/'\n",
    "filenames = list(set(next(walk(my_path), (None,None,[]))[2]))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "224145de-7657-4aa7-8f8c-6f3cf47baead",
   "metadata": {},
   "source": [
    "Information on the dataset variations: \n",
    "-\tNumber of variations for each set on average + KB and EB sizes on average ++ Ratio taille variations KB (tells us the number of noisy recipes)\n",
    "-\tIngredients repartition/diversity per recipes (Variable de contrôle – avg, min, ma) (save in Json)\n",
    "-\tTotal nb of unique words, avg term diversity per recipe + min max (save in Json) – KB / EB and variations\n",
    "-\tTotal of words cleaned (Text size raw vs cleaned)\n",
    "-\tNumber of name variations used to match recipes\n",
    "-\tCountry repartition (total of course, but per recipes the diversity of country variations and which countries are the most present for all variations and by cluster of countries)\n",
    "-\tInformation collected\n",
    "-\tType of recipes (Deserts, etc.) \n",
    "-\tOn average variations from same/different countries have how many ingredients and how many unique ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564b0a98-c4bc-491c-84c0-151bde615f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_cleaning(ingredient_list):\n",
    "\n",
    "    clean_list = []\n",
    "    for i in range(len(ingredient_list)):\n",
    "        recipe_doc = nlp(str(ingredient_list[i]))\n",
    "        temp_list = []\n",
    "        for token in recipe_doc:\n",
    "            temp_list.append(token.lemma_.lower())\n",
    "        if len(temp_list) > 0:\n",
    "            clean_text = ' '.join(temp_list)\n",
    "            clean_list.append(clean_text)\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14cd50a6-18bf-433b-bd40-8f4545a4c87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_info(index_list, recipe_dict, country_ref, index_name='Train_Variations'):\n",
    "    \n",
    "    # KB_rawtext_avg, train_rawtext_avg, valid_rawtext_avg, test_rawtext_avg = [], [] ,[] ,[]\n",
    "    # KB_cleantext_avg, train_cleantext_avg, valid_cleantext_avg, test_cleantext_avg = [], [] ,[] ,[]\n",
    "    # KB_uniq_words, train_uniq_words, valid_uniq_words, test_uniq_words = [],[],[],[]\n",
    "    # KB_clean_words, train_clean_words, valid_clean_words, test_clean_words = [], [], [], [] \n",
    "    \n",
    "    country_list, ingr_list, same_country_ingr, diff_country_ingr = [], [], [], []\n",
    "    recipe_raw_len, recipe_clean_len, uniq_raw_words, uniq_clean_words = [], [], [], []\n",
    "    \n",
    "    for index in index_list:\n",
    "        temp_dict = recipe_dict[index_name][index]\n",
    "        country = temp_dict['country']\n",
    "        country_list.append(country)\n",
    "        ingr_list.extend(ast.literal_eval(recipe_dict[index_name][index]['ingredient_list']))\n",
    "        \n",
    "        raw_recipe = ' '.join(recipe_dict[index_name][index]['recipe_raw'])\n",
    "        uniq_raw_words.append(len(set(raw_recipe.split())))\n",
    "        recipe_raw_len.append(len(raw_recipe.split()))\n",
    "        recipe_clean_len.append(len(recipe_dict[index_name][index]['recipe_clean'].split()))  ### type string\n",
    "        uniq_clean_words.append(len(set(recipe_dict[index_name][index]['recipe_clean'].split())))\n",
    "        \n",
    "        if country == country_ref:\n",
    "            same_country_ingr.extend(ast.literal_eval(recipe_dict[index_name][index]['ingredient_list']))\n",
    "        else:\n",
    "            diff_country_ingr.extend(ast.literal_eval(recipe_dict[index_name][index]['ingredient_list']))\n",
    "            \n",
    "    \n",
    "    #List of unique ingredients in the variation\n",
    "    uniq_ingr_list = list(set(text_cleaning(ingr_list)))\n",
    "    uniq_same_ingr_list = list(set(text_cleaning(same_country_ingr)))\n",
    "    uniq_diff_ingr_list = list(set(text_cleaning(diff_country_ingr)))\n",
    "    avg_raw_len, avg_clean_len, avg_raw_uniq, avg_clean_uniq = 0,0,0,0\n",
    "    if len(recipe_raw_len) > 0:\n",
    "        avg_raw_len = sum(recipe_raw_len) / len(recipe_raw_len)\n",
    "    if len(recipe_clean_len) > 0:\n",
    "        avg_clean_len = sum(recipe_clean_len) / len(recipe_clean_len)\n",
    "    if len(uniq_raw_words) > 0:\n",
    "        avg_raw_uniq = sum(uniq_raw_words) / len(uniq_raw_words)\n",
    "    if len(uniq_clean_words) > 0:\n",
    "        avg_clean_uniq = sum(uniq_clean_words) / len(uniq_clean_words)\n",
    "    \n",
    "    return country_list, uniq_ingr_list, uniq_same_ingr_list, uniq_diff_ingr_list, avg_raw_len, avg_clean_len, avg_raw_uniq, avg_clean_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83cea3b8-d797-4f18-9d0e-897b45a7b1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_new_ingr(var_ingr_list, same_country_list, diff_country_list, ref_ingr_list):\n",
    "    \n",
    "    new_ingr, new_ingr_same, new_ingr_diff = 0,0,0\n",
    "    for ingredient in var_ingr_list:\n",
    "        if ingredient not in ref_ingr_list:\n",
    "            new_ingr += 1\n",
    "            if ingredient in same_country_list:\n",
    "                new_ingr_same += 1\n",
    "            if ingredient in diff_country_list:\n",
    "                new_ingr_diff += 1\n",
    "    return new_ingr, new_ingr_same, new_ingr_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d3f12a8-75d7-4352-af1a-e39fb6d4101c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 501/501 [2:11:07<00:00, 15.70s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#######Lists to save as csv for info per recipe##########\n",
    "len_train_var, len_valid_var, len_test_var = [], [], []\n",
    "len_other_country_var, len_same_country_var = [], []\n",
    "len_KB = []\n",
    "ratio_KB_tot_var = []\n",
    "\n",
    "#number of recipes names used\n",
    "nb_names = []\n",
    "\n",
    "#Getting the recipe country and the most present country for variations\n",
    "recipe_country, top_1_country, top_2_country, top_3_country = [],[],[],[]\n",
    "train_country_div, valid_country_div, test_country_div, recipe_country_div = [],[],[],[] \n",
    "nb_same_country, nb_diff_country = [], []\n",
    "\n",
    "KB_ingr_size, train_ingr_size, valid_ingr_size, test_ingr_size = [], [], [], []\n",
    "same_country_ingr_size, diff_country_ingr_size = [], []\n",
    "total_new_ingr, train_new_ingr, valid_new_ingr, test_new_ingr = [], [], [], []\n",
    "same_country_new_ingr, diff_country_new_ingr = [], []\n",
    "\n",
    "#Countring the number of unique words and the length of raw and cleaned recipes\n",
    "KB_rawtext_avg, train_rawtext_avg, valid_rawtext_avg, test_rawtext_avg = [], [] ,[] ,[]\n",
    "KB_cleantext_avg, train_cleantext_avg, valid_cleantext_avg, test_cleantext_avg = [], [] ,[] ,[]\n",
    "KB_uniq_words, train_uniq_words, valid_uniq_words, test_uniq_words = [],[],[],[]\n",
    "KB_clean_words, train_clean_words, valid_clean_words, test_clean_words = [], [], [], [] \n",
    "\n",
    "#Stats for the KB sizes and the compared variation sizes\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    filename = filenames[k]\n",
    "    file_path = my_path + filename\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "    \n",
    "    KB_base = recipe_dict['Reference_Base']\n",
    "    KB_indexes = [item for item in KB_base.keys() if item!='AllIngredients']\n",
    "    \n",
    "    train_indexes = list(recipe_dict['Train_Variations'].keys())\n",
    "    valid_indexes = list(recipe_dict['Valid_Variations'].keys())\n",
    "    test_indexes = list(recipe_dict['Test_Variations'].keys())\n",
    "    \n",
    "    len_KB.append(len(KB_indexes))\n",
    "    len_train_var.append(len(train_indexes))\n",
    "    len_valid_var.append(len(valid_indexes))\n",
    "    len_test_var.append(len(test_indexes))\n",
    "    total_var = len(train_indexes) + len(valid_indexes) + len(test_indexes)\n",
    "    ratio_KB_tot_var.append(len(KB_indexes)/total_var)\n",
    "    \n",
    "    KB_country = recipe_dict['Country']\n",
    "    recipe_country.append(KB_country)\n",
    "    \n",
    "    #Nb of variation names used in the data collection\n",
    "    nb_names.append(len(recipe_dict['Name variations'].split(' | ')))\n",
    "\n",
    "    KB_ingr_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "    KB_ingr_size.append(len(KB_ingr_list))\n",
    "    \n",
    "    #Countring the number of unique words and the length of raw and cleaned recipes\n",
    "    temp_KB_rawtext, temp_KB_cleantext, temp_KB_uniq_words, temp_KB_clean_words = [], [], [], []\n",
    "    for index in KB_indexes:\n",
    "        sentences = recipe_dict['Reference_Base'][index]['recipe_raw']\n",
    "        raw_recipe = ' '.join(sentences)\n",
    "        temp_KB_uniq_words.append(len(set(raw_recipe.split())))\n",
    "        #temp_KB_rawtext.append(sum(len(sentence.split()) for sentence in sentences))\n",
    "        temp_KB_rawtext.append(len(raw_recipe.split()))\n",
    "        temp_KB_cleantext.append(len(recipe_dict['Reference_Base'][index]['recipe_clean'].split()))  ### type string\n",
    "        temp_KB_clean_words.append(len(set(recipe_dict['Reference_Base'][index]['recipe_clean'].split())))\n",
    "    \n",
    "    KBavg_raw_len = sum(temp_KB_rawtext) / len(temp_KB_rawtext)\n",
    "    KBavg_clean_len = sum(temp_KB_cleantext) / len(temp_KB_cleantext)\n",
    "    KBavg_raw_uniq = sum(temp_KB_uniq_words) / len(temp_KB_uniq_words)\n",
    "    KBavg_clean_uniq = sum(temp_KB_clean_words) / len(temp_KB_clean_words)\n",
    "    \n",
    "    KB_rawtext_avg.append(KBavg_raw_len)\n",
    "    KB_cleantext_avg.append(KBavg_clean_len)\n",
    "    KB_uniq_words.append(KBavg_raw_uniq)\n",
    "    KB_clean_words.append(KBavg_clean_uniq)\n",
    "\n",
    "    ## Getting all statistics for train, valid, test\n",
    "    #def get_info(index_list, recipe_dict, country_ref, index_name='Train_Variations'):\n",
    "    country_list_train, ingr_list_train, same_train_ingr, diff_train_ingr, \\\n",
    "    train_raw_len, trian_clean_len, trian_raw_uniq, train_clean_uniq = get_info(train_indexes, recipe_dict, KB_country, index_name='Train_Variations')\n",
    "    country_list_valid, ingr_list_valid, same_valid_ingr, diff_valid_ingr, \\\n",
    "    valid_raw_len, valid_clean_len, valid_raw_uniq, valid_clean_uniq = get_info(valid_indexes, recipe_dict, KB_country, index_name='Valid_Variations')\n",
    "    country_list_test, ingr_list_test, same_test_ingr, diff_test_ingr, \\\n",
    "    test_raw_len, test_clean_len, test_raw_uniq, test_clean_uniq = get_info(test_indexes, recipe_dict, KB_country, index_name='Test_Variations')\n",
    "    \n",
    "    \n",
    "    #Getting the recipe country and the most present country for variations\n",
    "    total_pays = country_list_train + country_list_valid + country_list_test\n",
    "    dict_pays = Counter(total_pays)\n",
    "    # Sort the dictionary items by value in descending order and get the top 3\n",
    "    top_3_keys = sorted(dict_pays, key=dict_pays.get, reverse=True)[:3]\n",
    "    same_country = dict_pays[KB_country]\n",
    "    diff_country = len(total_pays) - same_country\n",
    "    \n",
    "    #Country statistics\n",
    "    country1, country2, country3 = None, None, None\n",
    "    if len(top_3_keys) >= 1:\n",
    "        country1 = top_3_keys[0]\n",
    "    if len(top_3_keys) >= 2:\n",
    "        country2 = top_3_keys[1]\n",
    "    if len(top_3_keys) >= 3:\n",
    "        country3 = top_3_keys[2]\n",
    "    top_1_country.append(country1)\n",
    "    top_2_country.append(country2)\n",
    "    top_3_country.append(country3)\n",
    "    nb_same_country.append(same_country)\n",
    "    nb_diff_country.append(diff_country)\n",
    "    recipe_country_div.append(len(dict_pays))\n",
    "    train_country_div.append(len(list(set(country_list_train))))\n",
    "    valid_country_div.append(len(list(set(country_list_valid))))\n",
    "    test_country_div.append(len(list(set(country_list_test))))\n",
    "    \n",
    "    #ingredients statistics\n",
    "    same_country_tot = list(set(same_train_ingr + same_valid_ingr + same_test_ingr))\n",
    "    diff_country_tot = list(set(diff_train_ingr + diff_valid_ingr + diff_test_ingr))\n",
    "    tot_ingr_var = list(set(ingr_list_train + ingr_list_valid + ingr_list_test))\n",
    "    \n",
    "    train_ingr_size.append(len(ingr_list_train))\n",
    "    valid_ingr_size.append(len(ingr_list_valid))\n",
    "    test_ingr_size.append(len(ingr_list_test))\n",
    "    same_country_ingr_size.append(len(same_country_tot))\n",
    "    diff_country_ingr_size.append(len(diff_country_tot))\n",
    "    \n",
    "    new_ingr, same_new_inrg, diff_new_ingr = get_new_ingr(tot_ingr_var, same_country_tot, diff_country_tot, KB_ingr_list)\n",
    "    new_ingr_train, _, _ = get_new_ingr(ingr_list_train, same_train_ingr, diff_train_ingr, KB_ingr_list)\n",
    "    new_ingr_valid, _, _ = get_new_ingr(ingr_list_valid, same_valid_ingr, diff_valid_ingr, KB_ingr_list)\n",
    "    new_ingr_test, _, _ = get_new_ingr(ingr_list_test, same_test_ingr, diff_test_ingr, KB_ingr_list)\n",
    "    \n",
    "    \n",
    "    total_new_ingr.append(new_ingr)\n",
    "    train_new_ingr.append(new_ingr_train)\n",
    "    valid_new_ingr.append(new_ingr_valid)\n",
    "    test_new_ingr.append(new_ingr_test)\n",
    "    same_country_new_ingr.append(same_new_inrg)\n",
    "    diff_country_new_ingr.append(diff_new_ingr)\n",
    "    \n",
    "    ## Recipe sizes \n",
    "    train_rawtext_avg.append(train_raw_len)\n",
    "    valid_rawtext_avg.append(valid_raw_len)\n",
    "    test_rawtext_avg.append(test_raw_len)\n",
    "    train_cleantext_avg.append(trian_clean_len)\n",
    "    valid_cleantext_avg.append(valid_clean_len)\n",
    "    test_cleantext_avg.append(test_clean_len)\n",
    "    train_uniq_words.append(trian_raw_uniq)\n",
    "    valid_uniq_words.append(valid_raw_uniq)\n",
    "    test_uniq_words.append(test_raw_uniq)\n",
    "    train_clean_words.append(train_clean_uniq)\n",
    "    valid_clean_words.append(valid_clean_uniq)\n",
    "    test_clean_words.append(test_clean_uniq)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame({'ID_Name': filenames,\n",
    "                   'Nb recipes in KB': len_KB, 'Train - Nb variations': len_train_var, 'Valid - Nb variations': len_valid_var, 'Test - Nb variations': len_test_var, \n",
    "                   'Ratio recipes KB variations': ratio_KB_tot_var, 'Ref Country': recipe_country, 'Nb different names': nb_names, 'KB - Nb ingredients': KB_ingr_size,\n",
    "                   'KB - Text length':KB_rawtext_avg, 'Train Var - Text length': train_rawtext_avg, 'Valid Var - Text length': valid_rawtext_avg, \n",
    "                   'Test Var - Text length': test_rawtext_avg,\n",
    "                   'KB - Clean length':KB_cleantext_avg, 'Train Var - Clean length': train_cleantext_avg, 'Valid Var - Clean length': valid_cleantext_avg, \n",
    "                   'Test Var - Clean length': test_cleantext_avg,\n",
    "                   'KB - Nb Tokens':KB_uniq_words, 'Train Var - Nb Tokens': train_uniq_words, 'Valid Var - Nb Tokens': valid_uniq_words, 'Test Var - Nb Tokens': test_uniq_words,\n",
    "                   'KB - Clean Nb tokens':KB_clean_words, 'Train Var - Clean Nb tokens': train_clean_words, 'Valid Var - Clean Nb tokens': valid_clean_words, \n",
    "                   'Test Var - Clean Nb tokens': test_clean_words, 'Top1 Country': top_1_country, 'Top2 Country': top_2_country, 'Top3 Country': top_3_country, \n",
    "                   'Nb recipes same country': nb_same_country, 'Nb recipes different country': nb_diff_country, 'Total Nb different countries': recipe_country_div, \n",
    "                   'Train - Nb different country': train_country_div, 'Valid - Nb different country': valid_country_div, 'Test - Nb different country' : test_country_div,\n",
    "                   'Train - Nb ingredients': train_ingr_size, 'Valid - Nb ingredients': valid_ingr_size, 'Test - Nb ingredients': test_ingr_size, \n",
    "                   'Same Country - Nb ingredients': same_country_ingr_size, 'Different Country - Nb ingredients': diff_country_ingr_size, \n",
    "                   'Total - Nb new ingredients': total_new_ingr, 'Train - Nb new ingredients': train_new_ingr, 'Valid - Nb new ingredients': valid_new_ingr, \n",
    "                   'Test - Nb new ingredients': test_new_ingr, 'Same Country - Nb new ingredients': same_country_new_ingr,\n",
    "                   'Different Country - Nb new ingredients': diff_country_new_ingr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c50118c0-5909-43e7-baba-cae59991e66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('CulturalNovelty_DatasetStatistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985194ca-cdca-409f-8744-a65151b3550c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
